{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtBdSivJkVjyofb2Gvay8S"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#üöÄ DAY 9 ‚Äî Observability, Debugging & Evaluation for Agents"
      ],
      "metadata": {
        "id": "GCDNDiBGjuo1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Today we will learn how real teams debug, monitor, and evaluate agents ‚Äî not just ‚Äúhope they work‚Äù.\n",
        "\n",
        "**So far your agents can:**\n",
        "\n",
        "   - ‚úî plan\n",
        "   - ‚úî reason  \n",
        "   - ‚úî use tools\n",
        "  - ‚úî remember\n",
        "  - ‚úî access the web\n",
        "\n",
        "**But now we answer:**\n",
        "\n",
        "‚ùì How do I know my agent is correct, reliable, and improving?\n",
        "\n",
        "\n",
        "**Build observable, debuggable, and evaluable agents by:**\n",
        "\n",
        "- Logging thoughts, tool calls, and errors\n",
        "\n",
        "- Tracing agent execution\n",
        "\n",
        "- Evaluating correctness, reasoning quality, and tool usage"
      ],
      "metadata": {
        "id": "I4p4NKeAj6V8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üîπ 1Ô∏è‚É£ CORE TOPICS**\n",
        "\n",
        "**üîç Observability**\n",
        "\n",
        "- Execution traces\n",
        "\n",
        "- Step-by-step logs\n",
        "\n",
        "- Tool-call visibility\n",
        "\n",
        "- Latency & failure points\n",
        "\n",
        "**üß™ Evaluation**\n",
        "\n",
        "- Correctness evaluation\n",
        "\n",
        "- Reasoning quality\n",
        "\n",
        "- Tool-choice accuracy\n",
        "\n",
        "- Regression testing for agents\n",
        "\n",
        "**üõ† Debugging**\n",
        "\n",
        "- Prompt failures\n",
        "\n",
        "- Tool misuse\n",
        "\n",
        "- Infinite loops\n",
        "\n",
        "- Hallucinations"
      ],
      "metadata": {
        "id": "w2etPHWqk_0M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üîπ 2Ô∏è‚É£ WHY THIS MATTERS**\n",
        "\n",
        "Without observability:\n",
        "\n",
        "‚ùå You don‚Äôt know why the agent failed\n",
        "\n",
        "‚ùå You can‚Äôt improve prompts\n",
        "\n",
        "‚ùå You can‚Äôt deploy safely\n",
        "\n",
        "**With observability:**\n",
        "\n",
        "‚úî Faster debugging\n",
        "\n",
        "‚úî Measurable improvement\n",
        "\n",
        "‚úî Production readiness\n",
        "\n",
        "This is what separates hobby agents from real applications."
      ],
      "metadata": {
        "id": "qf32eh6Dlfpi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**‚úîÔ∏è Step 1 ‚Äî Enable Verbose Logging**\n",
        "\n",
        "üß† What is initialize_agent()?\n",
        "\n",
        "Think of initialize_agent() as a factory function.\n",
        "\n",
        "üëâ It builds an agent for you automatically instead of you writing:\n",
        "\n",
        "- prompts\n",
        "\n",
        "- reasoning loops\n",
        "\n",
        "- tool-selection logic\n",
        "\n",
        "So instead of manually coding ReAct, LangChain does it internally.\n",
        "\n",
        "**üß© Line-by-Line Explanation**\n",
        "\n",
        "\n",
        "1Ô∏è‚É£ tools\n",
        "\n",
        "    tools = [add_numbers, ai_fact, web_search]\n",
        "    #‚ÄúThese are the actions my agent is allowed to take.‚Äù\n",
        "\n",
        "2Ô∏è‚É£ llm\n",
        "\n",
        "    #‚ÄúUse this LLM to think, reason, and decide.‚Äù\n",
        "    llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "3Ô∏è‚É£ agent_type=\"zero-shot-react-description\"\n",
        "\n",
        "üîπ Zero-shot\n",
        "\n",
        "The agent is not given examples.\n",
        "\n",
        "It figures out:\n",
        "\n",
        "how to reason\n",
        "\n",
        "how to use tools\n",
        "\n",
        "purely from descriptions.\n",
        "\n",
        "üîπ ReAct\n",
        "\n",
        "Reason + Act.\n",
        "\n",
        "The agent:\n",
        "\n",
        "Thinks\n",
        "\n",
        "Decides to use a tool\n",
        "\n",
        "Executes tool\n",
        "\n",
        "Thinks again\n",
        "\n",
        "Repeats\n",
        "\n",
        "\n",
        "üîπ Description\n",
        "\n",
        "The agent uses:\n",
        "\n",
        "tool docstrings\n",
        "\n",
        "function descriptions\n",
        "\n",
        "to decide which tool to use.\n",
        "\n",
        "    example:\n",
        "    #Create a ReAct agent that can use tools by reading their descriptions, without examples\n",
        "\n",
        "    @tool\n",
        "    def add_numbers(a: int, b: int):\n",
        "        \"\"\"Add two numbers\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "4Ô∏è‚É£ verbose=True\n",
        "\n",
        "üîπ What does verbose mean?\n",
        "\n",
        "verbose=True means:\n",
        "\n",
        "üîä ‚ÄúShow me EVERYTHING the agent is thinking and doing.‚Äù\n",
        "\n",
        "**üß† Without verbose**\n",
        "\n",
        "You see only:\n",
        "\n",
        "    Final Answer: 15\n",
        "\n",
        "**üß† With verbose=True**\n",
        "\n",
        "You see:\n",
        "\n",
        "    Thought: I should calculate 5 + 10\n",
        "    Action: add_numbers\n",
        "    Action Input: {\"a\": 5, \"b\": 10}\n",
        "    Observation: 15\n",
        "    Thought: Now I can answer\n",
        "    Final Answer: 15\n",
        "\n",
        "\n",
        "In production ‚Üí verbose=False\n",
        "In learning ‚Üí ALWAYS True\n",
        "\n",
        "\n",
        "initialize_agent = \"Build me a smart agent\"\n",
        "\n",
        "tools            = \"Here are its\n",
        "hands\"\n",
        "\n",
        "llm              = \"Here is its\n",
        "brain\"\n",
        "\n",
        "agent_type       = \"How it should think\"\n",
        "\n",
        "verbose=True     = \"Show me its thoughts\"\n"
      ],
      "metadata": {
        "id": "adX0uVVimODD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent_type=\"zero-shot-react-description\",\n",
        "    verbose=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "brSgXsz5nRD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**‚úîÔ∏è Step 2 ‚Äî Add Structured Logging**\n",
        "\n",
        "üîπ What Is This Code Doing (High-Level)?\n",
        "\n",
        "This code is creating a simple logging system to track:\n",
        "\n",
        "- what step the agent is on\n",
        "\n",
        "- which tool it used\n",
        "\n",
        "- what result it got\n",
        "\n",
        "- when it happened\n",
        "\n",
        "Think of it as a flight recorder for your agent ‚úàÔ∏è\n",
        "\n",
        "\n",
        "**üîπ Line-by-Line Explanation**\n",
        "\n",
        "1Ô∏è‚É£ import time\n",
        "Used for:\n",
        "\n",
        "- ordering steps\n",
        "\n",
        "- measuring duration\n",
        "\n",
        "- debugging\n",
        "\n",
        "      import time\n",
        "      time.time()  # 1723456789.123\n",
        "\n",
        "2Ô∏è‚É£ logs = []\n",
        "\n",
        "- This list stores all agent actions.\n",
        "\n",
        "- Each action will be added as a dictionary.\n",
        "\n",
        "      logs = []\n",
        "\n",
        "3Ô∏è‚É£ def log_step(...)\n",
        "step ‚Üí description of what happened\n",
        "\n",
        "tool=None ‚Üí optional argument (default is None)\n",
        "\n",
        "result=None ‚Üí optional argument\n",
        "\n",
        "üëâ You can call this function with:\n",
        "\n",
        "just step or with tool and result\n",
        "\n",
        "\n",
        "      def log_step(step, tool=None, result=None):\n",
        "\n",
        "\n",
        "4Ô∏è‚É£ logs.append({ ... })\n",
        "\n",
        "Each log entry is a dictionary.\n",
        "\n",
        "    logs.append({\n",
        "5Ô∏è‚É£ \"timestamp\": time.time()\n",
        "\n",
        "Save when this step happened.\n",
        "\n",
        "Later you can:\n",
        "\n",
        "- sort logs\n",
        "\n",
        "- calculate duration between steps\n",
        "\n",
        "Example:\n",
        "\n",
        "end - start = execution_time\n",
        "\n",
        "    \"timestamp\": time.time(),\n",
        "\n",
        "\n",
        "**üîπ Mental Model (Remember This)**\n",
        "\n",
        "logs = agent diary\n",
        "log_step() = write in diary\n",
        "time.time() = when it happened"
      ],
      "metadata": {
        "id": "_zd9B_IPoLQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "logs = []\n",
        "\n",
        "def log_step(step, tool=None, result=None):\n",
        "    logs.append({\n",
        "        \"timestamp\": time.time(),\n",
        "        \"step\": step,\n",
        "        \"tool\": tool,\n",
        "        \"result\": result\n",
        "    })\n"
      ],
      "metadata": {
        "id": "4ST4kRSjoOTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**‚úîÔ∏è Step 3 ‚Äî Trace Tool Calls**\n",
        "\n"
      ],
      "metadata": {
        "id": "4MojaS4vqylQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_step(step):\n",
        "    start = time.time()\n",
        "    result = agent.run(step)\n",
        "    log_step(step, tool=\"agent\", result=result)\n",
        "    print(f\"Latency: {time.time() - start:.2f}s\")\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "rzhD90FEq0zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üîπ 5Ô∏è‚É£ AGENT EVALUATION (VERY IMPORTANT)**"
      ],
      "metadata": {
        "id": "O0B-kOvRq78d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(output, expected_keywords):\n",
        "    score = sum(1 for k in expected_keywords if k.lower() in output.lower())\n",
        "    return score / len(expected_keywords)\n"
      ],
      "metadata": {
        "id": "G6LFcVWcq7nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**‚úîÔ∏è Run Automated Tests**"
      ],
      "metadata": {
        "id": "gRYzHjVSrK0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tests = [\n",
        "    (\"Explain RAG\", [\"retrieval\", \"generation\"]),\n",
        "    (\"Add 5 and 10\", [\"15\"])\n",
        "]\n",
        "\n",
        "for task, expected in tests:\n",
        "    out = agent.run(task)\n",
        "    print(task, evaluate(out, expected))\n"
      ],
      "metadata": {
        "id": "CR-wvdEZrM19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VkMog9SApCm7"
      }
    }
  ]
}