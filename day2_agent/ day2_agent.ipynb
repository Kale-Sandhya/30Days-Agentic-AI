{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWaLTtYx5/Ms/rjpBb6Txh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kale-Sandhya/30Days-Agentic-AI/blob/main/%20%20day2_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ðŸ§­ Day 2 Summary â€“ Agentic AI Developer Setup & First Agent**\n",
        "\n",
        "Steps :\tWhat the code does\tHuman version\n",
        "\n",
        "1ï¸âƒ£\tInstall libraries\tâ€œGet the tools readyâ€\n",
        "\n",
        "2ï¸âƒ£\tLoad your API key\tâ€œLog in to OpenRouterâ€\n",
        "\n",
        "3ï¸âƒ£\tInitialize the brain (LLM)\tâ€œSet up ChatGPT modelâ€\n",
        "\n",
        "4ï¸âƒ£\tGive it a tool (math calculator)\tâ€œHand the AI a calculator ðŸ§®â€\n",
        "\n",
        "5ï¸âƒ£\tCreate an agent and run it\tâ€œAsk it to solve a problemâ€\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5WoYy9xGZybH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Installing Python libraries that make everything work.**\n",
        "| Library                 | What it does                                            | Why it matters                         |\n",
        "| ----------------------- | ------------------------------------------------------- | -------------------------------------- |\n",
        "| **langchain**           | The main framework for building AI agents and workflows | Lets you build smart LLM-based systems |\n",
        "| **langchain-community** | Extra tools (math, search, APIs, etc.)                  | Adds real-world functionality          |\n",
        "| **langchain-core**      | The low-level core of LangChain                         | Manages chains, agents, memory, etc.   |\n",
        "| **python-dotenv**       | Reads `.env` files that store API keys                  | Keeps your API keys secret             |\n",
        "| **openai**              | Official OpenAI library                                 | Needed for model communication         |\n"
      ],
      "metadata": {
        "id": "QRGB-tEpoPfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸªœ Step 1 â€” Install dependencies (run once)\n",
        "!pip install -q langchain langchain-community langchain-core python-dotenv openai"
      ],
      "metadata": {
        "id": "OQMfEr7uoLeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ðŸ§© What these do:**\n",
        "| Code               | Meaning                                                | Why we use it                                           |\n",
        "| ------------------ | ------------------------------------------------------ | ------------------------------------------------------- |\n",
        "| `initialize_agent` | Function that creates your AI agent                    | Combines tools + model into one system                  |\n",
        "| `AgentType`        | Defines *how* the agent thinks (its reasoning style)   | ZERO_SHOT_REACT_DESCRIPTION = Think â†’ Act â†’ Answer      |\n",
        "| `load_tools`       | Loads external â€œhelpersâ€ like calculator, search, etc. | So your agent can use them                              |\n",
        "| `ChatOpenAI`       | The LLM (language model) class                         | This connects LangChain to the OpenAI or OpenRouter API |\n",
        "| `os`               | Gives access to your system environment                | Used to store & read API keys                           |\n"
      ],
      "metadata": {
        "id": "oKQ2PYmaojhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸªœ Step 2 â€” Imports\n",
        "from langchain.agents import initialize_agent, AgentType, load_tools\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os"
      ],
      "metadata": {
        "id": "0mkiClxko80q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ðŸ’¡ OpenRouter is a platform that lets you access multiple AI models (GPT, Claude, Mistral, etc.) using one key.**\n",
        "\n",
        "\n",
        "*   OPENAI_API_KEY\tYour secret key from https://openrouter.ai\n",
        "\n",
        "*   OPENAI_API_BASE\tThe base API URL for OpenRouter (like a gateway)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3EwkEP9tpAME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸªœ Step 3 â€” Set your OpenRouter API key directly (no .env needed in Colab)\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Add Your API Key Here\"\n",
        "os.environ[\"OPENAI_API_BASE\"] = \"https://openrouter.ai/api/v1\""
      ],
      "metadata": {
        "id": "Lja8ts3Ppuy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Youâ€™re creating your AI brain (the LLM â€” Large Language Model).**\n",
        "\n",
        "Parameter\tMeaning\n",
        "model=\"gpt-3.5-turbo\"\tWhich model you want to use\n",
        "temperature=0.7\tControls creativity: 0 = logical, 1 = creative\n",
        "\n",
        "**ðŸ’¡ Example:**\n",
        "\n",
        "0.0 â†’ â€œsafeâ€ factual answers (good for math, coding)\n",
        "\n",
        "1.0 â†’ â€œcreativeâ€ answers (good for writing, brainstorming)"
      ],
      "metadata": {
        "id": "mR9EAGlupvhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸªœ Step 4 â€” Initialize the model\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)"
      ],
      "metadata": {
        "id": "nJAFmp_UrJza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LangChain agents can use tools â€” just like how humans use calculators or browsers.**\n",
        "\n",
        "**Tool\tDescription**\n",
        "\n",
        "\n",
        "\n",
        "*   \"llm-math\"\tLets the AI use a calculator for math problems\n",
        "\n",
        "*   This means the agent wonâ€™t â€œguessâ€ math answers â€” it uses a real math function.\n",
        "\n",
        "\n",
        "\n",
        "**ðŸ’¡ Example:**\n",
        "\n",
        "When you ask â€œWhat is 25% of 450?â€,\n",
        "the LLM thinks: â€œHmm, this is a math problemâ€ â†’ uses llm-math â†’ gets 112.5."
      ],
      "metadata": {
        "id": "ldPEfUKSrLoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸªœ Step 5 â€” Load the math tool\n",
        "tools = load_tools([\"llm-math\"], llm=llm)"
      ],
      "metadata": {
        "id": "QMzzLq47r1yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weâ€™re combining:**\n",
        "\n",
        "\n",
        "*   The brain (llm)\n",
        "\n",
        "*   The tools (like llm-math)\n",
        "\n",
        "*   The thinking style (AgentType)\n",
        "\n",
        "**ðŸ§  Key concepts:**\n",
        "\n",
        "| Parameter                               | Meaning                                                                                  |\n",
        "| --------------------------------------- | ---------------------------------------------------------------------------------------- |\n",
        "| `tools`                                 | The list of tools the agent can use                                                      |\n",
        "| `llm`                                   | The model you created earlier                                                            |\n",
        "| `AgentType.ZERO_SHOT_REACT_DESCRIPTION` | The reasoning strategy â€” it **reads the question, reasons, chooses a tool, and answers** |\n",
        "| `verbose=True`                          | Shows the internal thought process in the Colab output                                   |\n",
        "\n",
        "\n",
        "\n",
        "**ðŸ’¡ AgentType.ZERO_SHOT_REACT_DESCRIPTION**\n",
        "\n",
        "**â€œZero-shotâ€** â†’ it doesnâ€™t need examples or prior training\n",
        "\n",
        "**â€œReactâ€** â†’ it reasons then acts\n",
        "\n",
        "This is what makes the agent intelligent â€” it decides what to do dynamically."
      ],
      "metadata": {
        "id": "CsEV1kaAsEOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ðŸªœ Step 6 â€” Create the agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "yt0MLJRWtDSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Code               | Meaning                                           |\n",
        "| ------------------ | ------------------------------------------------- |\n",
        "| `query`            | The question youâ€™re asking                        |\n",
        "| `agent.run(query)` | Tells the agent to think â†’ choose a tool â†’ answer |\n",
        "| `print(...)`       | Displays the final result                         |\n"
      ],
      "metadata": {
        "id": "jJagtApJtHSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ðŸªœ Step 7 â€” Test it!\n",
        "query = \"What is 25% of 450?\"\n",
        "response = agent.run(query)\n",
        "print(\"\\n Final Answer:\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "oBuUUCVVg_1d",
        "outputId": "fa4a50c4-964e-471d-aa70-a8fe08f95f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should use the calculator tool to find the answer to this math question.\n",
            "Action: Calculator\n",
            "Action Input: 25% of 450\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 112.5\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: 112.5\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "âœ… Final Answer: 112.5\n"
          ]
        }
      ]
    }
  ]
}
