{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgw5jizUrg0wxWLHNV2qiC"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Multi-Step Reasoning Agents (ReAct + ToT)**"
      ],
      "metadata": {
        "id": "C1w1NwUWNLQT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Earlier days your agent could:**\n",
        "-- Call tools\n",
        "\n",
        "- Search web\n",
        "\n",
        "- Use memory\n",
        "\n",
        "- Answer single-step tasks\n",
        "\n",
        "But real-world problems are multi-step, like:\n",
        "\n",
        "‚ÄúResearch RAG, explain it simply, and then calculate 5 + 10‚Äù\n",
        "\n",
        "**This requires:**\n",
        "\n",
        "- Understanding the task\n",
        "\n",
        "- Breaking it into parts\n",
        "\n",
        "- Choosing tools at the right time\n",
        "\n",
        "- Combining results\n",
        "\n",
        "That‚Äôs what CoT, ReAct, ToT solve."
      ],
      "metadata": {
        "id": "wVMbqzVae4jJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Following are advanced reasoning strategies so your agent can:**\n",
        "\n",
        "- Think step by step (Chain-of-Thought / CoT)\n",
        "\n",
        "- React dynamically to tool results (ReAct)\n",
        "\n",
        "- Break complex tasks into sub-tasks recursively (Tree-of-Thought / ToT)\n",
        "\n",
        "This is what expert-level Agentic AI does."
      ],
      "metadata": {
        "id": "R4_nO7DCNVPl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Topic                         | Description                                                          |\n",
        "| ----------------------------- | -------------------------------------------------------------------- |\n",
        "| **CoT (Chain-of-Thought)**    | Agent reasons step-by-step before acting                             |\n",
        "| **ReAct (Reason + Act)**      | Agent alternates reasoning + tool usage dynamically                  |\n",
        "| **ToT (Tree-of-Thought)**     | Agent breaks tasks into sub-tasks recursively and evaluates branches |\n",
        "| **Stepwise Planning**         | How to combine CoT + ToT for complex multi-step problems             |\n",
        "| **Memory + Tool Integration** | Use memory & tools during reasoning                                  |\n"
      ],
      "metadata": {
        "id": "H-CPbufsN2pd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üîπ 2Ô∏è‚É£ WHY THIS IS IMPORTANT\n",
        "\n",
        "Without CoT / ReAct / ToT, your agent may:\n",
        "\n",
        "‚ùå Make mistakes\n",
        "\n",
        "‚ùå Choose the wrong tool\n",
        "\n",
        "‚ùå Fail on multi-step reasoning\n",
        "\n",
        "With these strategies, your agent becomes autonomous, resilient, and practical."
      ],
      "metadata": {
        "id": "D35fIL9ZN8dA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1Ô∏è‚É£ Chain-of-Thought (CoT) ‚Äî Thinking Step by Step**\n",
        "üîπ What it is\n",
        "\n",
        "CoT means:\n",
        "\n",
        "The agent reasons internally in steps before answering.\n",
        "\n",
        "Human example:\n",
        "\n",
        "‚ÄúI need to explain RAG ‚Üí I should define it ‚Üí maybe give an example ‚Üí then answer.‚Äù\n",
        "\n",
        "**üîπ Why it matters**\n",
        "\n",
        "Without CoT:\n",
        "\n",
        "Agent jumps to answers\n",
        "\n",
        "Makes logical mistakes\n",
        "\n",
        "With CoT:\n",
        "\n",
        "Agent slows down\n",
        "\n",
        "Thinks clearly\n",
        "\n",
        "Handles math & logic better\n",
        "\n",
        "üîπ In your code\n",
        "\n",
        "This part üëá forces CoT:\n",
        "\n",
        "- Think step-by-step (Chain-of-Thought)\n",
        "\n",
        "\n",
        "And this output section:\n",
        "\n",
        "      \"thoughts\": [\"step1\", \"step2\", \"...\"]\n",
        "\n",
        "\n",
        "üëâ You are explicitly asking the model to show reasoning steps.\n",
        "\n",
        "**2Ô∏è‚É£ ReAct (Reason + Act) ‚Äî Think ‚Üí Act ‚Üí Think ‚Üí Act**\n",
        "üîπ What it is\n",
        "\n",
        "ReAct means:\n",
        "\n",
        "The agent alternates between reasoning and using tools\n",
        "\n",
        "Human example:\n",
        "\n",
        "Think: ‚ÄúI don‚Äôt know this‚Äù\n",
        "\n",
        "Act: Google it\n",
        "\n",
        "Think: ‚ÄúNow I understand‚Äù\n",
        "\n",
        "Act: Calculate something\n",
        "\n",
        "Think: ‚ÄúCombine answer‚Äù\n",
        "\n",
        "**üîπ Why it matters**\n",
        "\n",
        "Without ReAct:\n",
        "\n",
        "Agent guesses\n",
        "\n",
        "Doesn‚Äôt know when to use tools\n",
        "\n",
        "With ReAct:\n",
        "\n",
        "Agent decides:\n",
        "\n",
        "‚ÄúShould I calculate?‚Äù\n",
        "\n",
        "‚ÄúShould I search?‚Äù\n",
        "\n",
        "‚ÄúShould I just explain?‚Äù\n",
        "\n",
        "üîπ In your code (VERY IMPORTANT)\n",
        "\n",
        "Tools:\n",
        "\n",
        "        @tool\n",
        "        def add_numbers(a: int, b: int):\n",
        "        return a + b\n",
        "\n",
        "  Tool plan output:\n",
        "\n",
        "                \"tool_plan\": [\n",
        "                  {\"tool\": \"add_numbers\", \"args\": {\"a\": 5, \"b\": 10}}\n",
        "                ]\n",
        "\n",
        "\n",
        "üëâ The LLM decides the tool,\n",
        "üëâ Your Python code executes it.\n",
        "\n",
        "This separation is core Agentic AI.\n",
        "\n",
        " **3Ô∏è‚É£ Tree-of-Thought (ToT) ‚Äî Break Big Problems Into Smaller Problems**\n",
        "üîπ What it is\n",
        "\n",
        "ToT means:\n",
        "\n",
        "Instead of 1 linear thought, the agent explores multiple sub-thoughts recursively\n",
        "\n",
        "Human example:\n",
        "\n",
        "‚ÄúLearn Agentic AI‚Äù\n",
        "\n",
        "Step 1: Basics\n",
        "\n",
        "Step 2: Tools\n",
        "\n",
        "Step 3: Memory\n",
        "\n",
        "Step 4: Planning\n",
        "\n",
        "Step 5: Evaluation\n",
        "\n",
        "Each step can be broken again.\n",
        "\n",
        "That‚Äôs a tree, not a line.\n",
        "\n",
        "\n",
        "**üîπ Why it matters**\n",
        "\n",
        "Without ToT:\n",
        "\n",
        "- Agent handles only simple tasks\n",
        "\n",
        "With ToT:\n",
        "\n",
        "- Agent solves:\n",
        "\n",
        "- Research tasks\n",
        "\n",
        "- Planning tasks\n",
        "\n",
        "- Multi-day workflows\n",
        "\n",
        "- Complex reasoning\n",
        "\n",
        "üîπ In your code (key insight)\n",
        "\n",
        "    def tot_task(task, depth=0):\n",
        "\n",
        "\n",
        "This function calls itself üëá\n",
        "\n",
        "\n",
        "    results.append(tot_task(subtask, depth + 1))\n",
        "\n",
        "\n",
        "That is recursion ‚Üí core of ToT.\n",
        "\n",
        "Each ‚Äúthought‚Äù becomes a new task.\n",
        "\n",
        "**4Ô∏è‚É£ How CoT + ReAct + ToT Work Together**\n",
        "\n",
        "Let‚Äôs take your test:\n",
        "\n",
        "\"Explain RAG and calculate 5 + 10\"\n",
        "\n",
        "üß† Agent internal flow:\n",
        "\n",
        "- CoT\n",
        "\n",
        "Step 1: Explain RAG\n",
        "\n",
        "Step 2: Calculate 5 + 10\n",
        "\n",
        "- ReAct\n",
        "\n",
        "Step 1: Use ai_fact\n",
        "\n",
        "Step 2: Use add_numbers\n",
        "\n",
        "- ToT\n",
        "\n",
        "Each step becomes a subtask\n",
        "\n",
        "Each subtask can have its own reasoning\n",
        "\n",
        "üî• This is expert-level agent behavior."
      ],
      "metadata": {
        "id": "l2GYxTqFfs9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Explaination"
      ],
      "metadata": {
        "id": "xusiMsmDi-U6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain_openai import ChatOpenAI  #Used to talk to OpenAI models.\n",
        "from langchain.chains import LLMChain\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "collapsed": true,
        "id": "enY_UqhZde0Y",
        "outputId": "c08c8b97-feae-48fe-d011-8bb317ef1513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_openai'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2849090581.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Used to talk to OpenAI models.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_openai'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now we want:**\n",
        "\n",
        "Prompt template\n",
        "\n",
        "Structured execution\n",
        "\n",
        "Reusability\n",
        "\n",
        "    LLMChain = Prompt + LLM + Execution logic bundled together\n",
        "\n",
        "**üß† Meaning: **\n",
        "\n",
        "‚ÄúWhenever I give input ‚Üí follow this prompt ‚Üí call LLM.‚Äù"
      ],
      "metadata": {
        "id": "8opQgdWnd9mD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "llm.invoke(prompt)"
      ],
      "metadata": {
        "id": "WmefCw0Wdpfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your prompt now has variables:\n",
        "\n",
        "    User Task: {task}\n",
        "\n",
        "\n",
        "PromptTemplate safely injects values."
      ],
      "metadata": {
        "id": "YITOXPDVedQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PromptTemplate.from_template(\"Hello {name}\")\n"
      ],
      "metadata": {
        "id": "Hw0NH8eGegu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This converts a normal Python function into an agent tool.\n",
        "\n",
        "It adds metadata so an LLM can:\n",
        "\n",
        "  -  Discover it\n",
        "\n",
        "   - Call it\n",
        "\n",
        "  - Pass arguments"
      ],
      "metadata": {
        "id": "QKxRc73Kem-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n"
      ],
      "metadata": {
        "id": "ExSVtajKejXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The LLM now returns JSON, not plain text.\n",
        "\n",
        "We must parse:\n",
        "\n",
        "    json.loads(output)\n"
      ],
      "metadata": {
        "id": "DtAVjNMAeyn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n"
      ],
      "metadata": {
        "id": "v41v76Vuexmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    @tool\n",
        "tells LangChain:\n",
        "\n",
        "‚ÄúThis function can be used by an agent.‚Äù\n",
        "\n",
        "\n",
        "**üß© Syntax:**'\n",
        "\n",
        "    a: int ‚Üí type hint (helps LLM understand arguments)\n",
        "\n",
        "    Return value ‚Üí tool output"
      ],
      "metadata": {
        "id": "MmdmU5xce827"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def add_numbers(a: int, b: int):\n",
        "    return a + b\n"
      ],
      "metadata": {
        "id": "9Uk4mDB3e70E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The agent will name the tool, not call it directly.\n",
        "\n",
        "So we need:\n",
        "\n",
        "    tools[tool_name].run(...)"
      ],
      "metadata": {
        "id": "0ziMRY1GfaJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = {\"add_numbers\": add_numbers, \"ai_fact\": ai_fact}\n"
      ],
      "metadata": {
        "id": "DnoAK59xfYKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Structured machine-readable plan ‚úÖ**\n",
        "\n",
        "    \"thoughts\": [\"step1\", \"step2\"]\n",
        "\n",
        "\n",
        "üß† Thoughts = reasoning steps\n",
        "\n",
        "      \"tool_plan\": [{\"tool\": \"...\", \"args\": {}}]\n",
        "\n",
        "\n",
        "üß† Tool plan = what to execute in Python"
      ],
      "metadata": {
        "id": "PTQ7kMHZf3O1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"thoughts\": [\"step1\", \"step2\"]\n",
        "\"tool_plan\": [{\"tool\": \"...\", \"args\": {}}]\n"
      ],
      "metadata": {
        "id": "LI4fqikkf9-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now execution becomes:**\n",
        "\n",
        "    chain.run(task=\"...\")\n",
        "\n",
        "\n",
        "Instead of:\n",
        "\n",
        "    llm.invoke(prompt)\n",
        "\n",
        "**üß† Think of LLMChain as:**\n",
        "\n",
        "‚ÄúA reasoning engine with a fixed brain + instruction"
      ],
      "metadata": {
        "id": "X49I9SMZgQ_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=PromptTemplate.from_template(react_prompt)\n",
        ")\n"
      ],
      "metadata": {
        "id": "Da4SS9vpgQNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üîπ STEP 5 ‚Äî ReAct Execution Logic (CORE AGENT LOGIC)**"
      ],
      "metadata": {
        "id": "-0Qs1BqtiGwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_react_task(task):  #This is your agent controller"
      ],
      "metadata": {
        "id": "887QSXMJgcri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ü§î What happens here?\n",
        "\n",
        "-  Task injected into prompt\n",
        "\n",
        "-  LLM reasons\n",
        "\n",
        "-  Returns JSON plan"
      ],
      "metadata": {
        "id": "fC4zv_-3g12n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = chain.run(task=task)"
      ],
      "metadata": {
        "id": "ws9O8eKoggb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM ‚Üí text\n",
        "Python ‚Üí dictionary"
      ],
      "metadata": {
        "id": "FvuF5TFnhDwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plan = json.loads(output)\n"
      ],
      "metadata": {
        "id": "PDt0xZF1g9Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† The agent told us what tools to run"
      ],
      "metadata": {
        "id": "19XDsCfvhKN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for step in plan[\"tool_plan\"]:\n"
      ],
      "metadata": {
        "id": "9_RqIR-jhJgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß© Syntax explained:\n",
        "\n",
        "**args ‚Üí dictionary unpacking\n",
        "\n",
        "run() ‚Üí LangChain tool execution"
      ],
      "metadata": {
        "id": "WmiYGjE_hN7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = tools[tool_name].run(**args)\n"
      ],
      "metadata": {
        "id": "J0XnHy6ahNWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üß† Final agent output** =\n",
        "Thinking + Actions"
      ],
      "metadata": {
        "id": "TdKYesR3hUjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "return {\"thoughts\": plan[\"thoughts\"], \"results\": results}\n"
      ],
      "metadata": {
        "id": "CJPhcatxhTx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **STEP 6 ‚Äî Tree-of-Thought (BIG CONCEPT)**\n",
        "\n",
        "üÜï RECURSION\n",
        "\n",
        "Function calling itself = tree structure.\n",
        "\n",
        "**if depth > 2:**\n",
        "üß† Safety stop ‚Üí prevents infinite loops\n",
        "\n",
        "\n",
        "    for subtask in output[\"thoughts\"]:\n",
        "\n",
        "**üÜï Key Insight**\n",
        "\n",
        "Thoughts become new tasks.\n",
        "\n",
        "    results.append(tot_task(subtask, depth + 1))\n",
        "\n",
        "üî• This is Tree-of-Thought\n",
        "\n",
        "Each thought ‚Üí branch ‚Üí sub-branch"
      ],
      "metadata": {
        "id": "Ow0Uhi1Ohb6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tot_task(task, depth=0):\n"
      ],
      "metadata": {
        "id": "iG8wSlL6hnTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Program:"
      ],
      "metadata": {
        "id": "UVIBcmrwi33b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.tools import tool\n",
        "import json\n",
        "\n",
        "#‚úîÔ∏è Step 2 ‚Äî Tools (Keep Previous + Calculator)\n",
        "@tool\n",
        "def add_numbers(a: int, b: int):\n",
        "    return a + b\n",
        "\n",
        "@tool\n",
        "def ai_fact(topic: str):\n",
        "    facts = {\"rag\": \"RAG = Retrieval-Augmented Generation\"}\n",
        "    return facts.get(topic.lower(), \"No fact found\")\n",
        "\n",
        "tools = {\"add_numbers\": add_numbers, \"ai_fact\": ai_fact}\n",
        "\n",
        "#‚úîÔ∏è Step 3 ‚Äî CoT + ReAct Prompt Template\n",
        "\n",
        "react_prompt = \"\"\"\n",
        "You are a ReAct Agent.\n",
        "- Think step-by-step (Chain-of-Thought)\n",
        "- Decide whether to use a tool or continue reasoning\n",
        "- Execute steps sequentially\n",
        "\n",
        "User Task: {task}\n",
        "\n",
        "Return JSON:\n",
        "{{\n",
        "  \"thoughts\": [\"step1\", \"step2\", \"...\"],\n",
        "  \"tool_plan\": [{{\"tool\": \"...\", \"args\": {{}}}}]\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "#‚úîÔ∏è Step 4 ‚Äî Initialize LLM\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
        "chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(react_prompt))\n",
        "\n",
        "#‚úîÔ∏è Step 5 ‚Äî Execute ReAct Steps\n",
        "def run_react_task(task):\n",
        "    output = chain.run(task=task)\n",
        "    plan = json.loads(output)\n",
        "\n",
        "    results = []\n",
        "    for step in plan[\"tool_plan\"]:\n",
        "        tool_name = step[\"tool\"]\n",
        "        args = step[\"args\"]\n",
        "        result = tools[tool_name].run(**args)\n",
        "        results.append({\"tool\": tool_name, \"result\": result})\n",
        "\n",
        "    return {\"thoughts\": plan[\"thoughts\"], \"results\": results}\n",
        "\n",
        "#‚úîÔ∏è Step 6 ‚Äî Tree-of-Thought (Recursive Planning)\n",
        "def tot_task(task, depth=0):\n",
        "    if depth > 2:  # limit recursion\n",
        "        return {\"task\": task, \"result\": \"Max depth reached\"}\n",
        "\n",
        "    output = run_react_task(task)\n",
        "    results = []\n",
        "    for subtask in output[\"thoughts\"]:\n",
        "        results.append(tot_task(subtask, depth + 1))\n",
        "    return {\"task\": task, \"results\": results}\n",
        "\n",
        "\n",
        "#‚úîÔ∏è Step 7 ‚Äî Test Your Agent\n",
        "task = \"Explain RAG and calculate 5 + 10\"\n",
        "tot_result = tot_task(task)\n",
        "print(json.dumps(tot_result, indent=2))\n",
        "\n"
      ],
      "metadata": {
        "id": "IcvfzkT-jBk1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}