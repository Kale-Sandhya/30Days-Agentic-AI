{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFXEYVnIFZUptZ50rjIc0N"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**üß† Day 3: Memory & Context in Agents**\n",
        "\n",
        "\"**memory**\" refers to the system's ability to store, retrieve, and utilize information from past interactions and experiences over time to inform current and future decisions and actions\n",
        "\n",
        "**üå± 1. What ‚ÄúMemory‚Äù Means in AI Agents**\n",
        "\n",
        "Without memory, your chatbot is like a goldfish üê† ‚Äî it forgets everything after every turn.\n",
        "\n",
        "With memory, it becomes like a human assistant üß† ‚Äî it remembers what you said earlier.\n",
        "\n",
        "| Type              | Description                                    | Example                                              |\n",
        "| ----------------- | ---------------------------------------------- | ---------------------------------------------------- |\n",
        "| üïí **Short-term** | Keeps recent chat history                      | ‚ÄúYou: Hi, I‚Äôm Sandhya.‚Äù ‚Üí ‚ÄúYour name is Sandhya.‚Äù    |\n",
        "| üìö **Long-term**  | Saves facts for later use (even after restart) | ‚ÄúYou like Python & AI‚Äù ‚Äî remembered across sessions. |\n"
      ],
      "metadata": {
        "id": "oi5YdFtmP42a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**üß† Key LangChain Memory Types**\n",
        "| Memory Type                      | What It Does                           | Use Case             |\n",
        "| -------------------------------- | -------------------------------------- | -------------------- |\n",
        "| `ConversationBufferMemory`       | Stores **all chat turns** (short-term) | Small sessions       |\n",
        "| `ConversationSummaryMemory`      | Keeps a **summary** (for long chats)   | Large conversations  |\n",
        "| `ConversationBufferWindowMemory` | Keeps **only last few** turns          | Real-time assistants |\n"
      ],
      "metadata": {
        "id": "7dPIDIxBRKNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1 ‚Äî Install Dependencies\n",
        "!pip install -q langchain langchain-community langchain-core langchain-openai python-dotenv openai"
      ],
      "metadata": {
        "id": "wu6cr-p_BcuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ü™ú Step 2 ‚Äî Import and Setup\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Add your API Key\"\n",
        "os.environ[\"OPENAI_API_BASE\"] = \"https://openrouter.ai/api/v1\""
      ],
      "metadata": {
        "id": "vlaBTH_bBlSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   **ChatOpenAI** ‚Üí connects LangChain to your OpenRouter API.\n",
        "\n",
        "*   **model=\"gpt-3.5-turbo\"** ‚Üí the brain model\n",
        "\n",
        "\n",
        "*   **temperature=0.7**‚Üí creativity (0 = logical, 1 = creative).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ".\n",
        "\n"
      ],
      "metadata": {
        "id": "-5WBLlInSCAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3 ‚Äî Initialize the Model (your agent‚Äôs ‚Äúbrain‚Äù)\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "# Initialize the model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0.7\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "FoIM7PwRByab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4 ‚Äî Add Memory (the ‚Äúmind‚Äù of the agent)**\n",
        "\n",
        "\n",
        "\n",
        "*    Short-Term Memory (Buffer)\n",
        "\n",
        "    memory = ConversationBufferMemory()\n",
        "(It remembers everything you said in the current chat.)\n",
        "\n",
        "---\n",
        "*   Summarized Memory\n",
        "   \n",
        "    memory = ConversationSummaryMemory(llm=llm)\n",
        "\n",
        "   (It summarizes older messages to keep context compact.)\n",
        "\n"
      ],
      "metadata": {
        "id": "e6W4Y-aDSn41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add memory (short-term contextual memory)\n",
        "memory = ConversationBufferMemory()"
      ],
      "metadata": {
        "id": "dIQyFDoZUNAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*    ConversationChain connects the LLM + Memory.\n",
        "\n",
        "*    verbose=True ‚Üí shows internal reasoning/logs.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uagmbQGAUYGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create conversation chain\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "print(\"Memory Agent Ready! Let's chat.\\n\")"
      ],
      "metadata": {
        "id": "i2qz63n4UYkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "while True:\n",
        "    query = input(\"You: \")\n",
        "    if query.lower() == \"exit\":\n",
        "        break\n",
        "    response = conversation.predict(input=query)\n",
        "    print(\"Agent:\", response)\n"
      ],
      "metadata": {
        "id": "oeSDrqLIC30b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the Conversation\n",
        "with open(\"memory_summary.txt\", \"w\") as f:\n",
        "    f.write(memory.buffer if hasattr(memory, \"buffer\") else \"No buffer available.\")\n",
        "print(\"üíæ Conversation saved!\")"
      ],
      "metadata": {
        "id": "umEM6w1JUxUs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}